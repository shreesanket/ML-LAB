{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Jki9qa6vFvk-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PqhKbOHdAeVa",
        "outputId": "e545d68b-c59d-483a-d98c-bfeb3e6005d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columns with missing values:\n",
            " Series([], dtype: int64)\n",
            "\n",
            "Categorical Columns:\n",
            " Index(['Gender', 'CLASS'], dtype='object')\n",
            "\n",
            "Preprocessed Diabetes Dataset:\n",
            "         ID  No_Pation       AGE      Urea        Cr     HbA1c      Chol  \\\n",
            "0  0.707921  -0.154715 -0.422575 -0.063109 -0.684758 -1.307234 -0.516819   \n",
            "2  0.362226  -0.085484 -0.422575 -0.063109 -0.684758 -1.307234 -0.516819   \n",
            "3  1.458332   0.006088 -0.422575 -0.063109 -0.684758 -1.307234 -0.516819   \n",
            "4  0.716353  -0.117220 -2.419194  1.207777 -0.684758 -1.307234  0.101811   \n",
            "5  1.264406  -0.117217 -1.009816 -1.333995 -1.623789 -1.663952 -1.665703   \n",
            "\n",
            "         TG       HDL       LDL      VLDL       BMI  Gender_M  Gender_f  \\\n",
            "0 -1.155276  3.231531 -1.173944 -0.479090 -1.110069       0.0       0.0   \n",
            "2 -1.155276  3.231531 -1.173944 -0.479090 -1.110069       0.0       0.0   \n",
            "3 -1.155276  3.231531 -1.173944 -0.479090 -1.110069       0.0       0.0   \n",
            "4 -1.067927 -0.900659 -0.577882 -0.543007 -1.744138       1.0       0.0   \n",
            "5 -1.067927 -0.384136 -1.074600 -0.543007 -1.744138       0.0       0.0   \n",
            "\n",
            "   CLASS_N   CLASS_P  CLASS_Y  CLASS_Y   \n",
            "0       0.0      0.0      0.0       0.0  \n",
            "2       0.0      0.0      0.0       0.0  \n",
            "3       0.0      0.0      0.0       0.0  \n",
            "4       0.0      0.0      0.0       0.0  \n",
            "5       0.0      0.0      0.0       0.0  \n",
            "Columns with missing values:\n",
            " Series([], dtype: int64)\n",
            "\n",
            "Categorical Columns:\n",
            " Index(['workclass', 'education', 'marital-status', 'occupation',\n",
            "       'relationship', 'race', 'gender', 'native-country', 'income'],\n",
            "      dtype='object')\n",
            "\n",
            "Preprocessed Adult Income Dataset:\n",
            "        age    fnlwgt  educational-num  capital-gain  capital-loss  \\\n",
            "0 -0.981833  0.440334        -1.254874     -0.242946     -0.035131   \n",
            "1 -0.013906 -1.005770        -0.438923     -0.242946     -0.035131   \n",
            "2 -0.758466  1.603113         0.785004     -0.242946     -0.035131   \n",
            "3  0.432829 -0.261447        -0.030947      3.102814     -0.035131   \n",
            "4 -1.503025 -0.861326        -0.030947     -0.242946     -0.035131   \n",
            "\n",
            "   hours-per-week  workclass_Federal-gov  workclass_Local-gov  \\\n",
            "0        0.013070                    0.0                  0.0   \n",
            "1        0.909086                    0.0                  0.0   \n",
            "2        0.013070                    0.0                  1.0   \n",
            "3        0.013070                    0.0                  0.0   \n",
            "4       -0.882945                    0.0                  0.0   \n",
            "\n",
            "   workclass_Never-worked  workclass_Private  ...  native-country_Puerto-Rico  \\\n",
            "0                     0.0                1.0  ...                         0.0   \n",
            "1                     0.0                1.0  ...                         0.0   \n",
            "2                     0.0                0.0  ...                         0.0   \n",
            "3                     0.0                1.0  ...                         0.0   \n",
            "4                     0.0                0.0  ...                         0.0   \n",
            "\n",
            "   native-country_Scotland  native-country_South  native-country_Taiwan  \\\n",
            "0                      0.0                   0.0                    0.0   \n",
            "1                      0.0                   0.0                    0.0   \n",
            "2                      0.0                   0.0                    0.0   \n",
            "3                      0.0                   0.0                    0.0   \n",
            "4                      0.0                   0.0                    0.0   \n",
            "\n",
            "   native-country_Thailand  native-country_Trinadad&Tobago  \\\n",
            "0                      0.0                             0.0   \n",
            "1                      0.0                             0.0   \n",
            "2                      0.0                             0.0   \n",
            "3                      0.0                             0.0   \n",
            "4                      0.0                             0.0   \n",
            "\n",
            "   native-country_United-States  native-country_Vietnam  \\\n",
            "0                           1.0                     0.0   \n",
            "1                           1.0                     0.0   \n",
            "2                           1.0                     0.0   \n",
            "3                           1.0                     0.0   \n",
            "4                           1.0                     0.0   \n",
            "\n",
            "   native-country_Yugoslavia  income_>50K  \n",
            "0                        0.0          0.0  \n",
            "1                        0.0          0.0  \n",
            "2                        0.0          1.0  \n",
            "3                        0.0          1.0  \n",
            "4                        0.0          0.0  \n",
            "\n",
            "[5 rows x 101 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler, OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Load Diabetes dataset (update with your file path in Google Colab)\n",
        "diabetes_df = pd.read_csv(\"/content/Dataset of Diabetes .csv\")\n",
        "\n",
        "# Load Adult Income dataset (update with your file path in Google Colab)\n",
        "adult_income_df = pd.read_csv(\"/content/adult.csv\")\n",
        "\n",
        "# Function for data cleaning and transformations\n",
        "def preprocess_data(df):\n",
        "    # 1. Data Cleaning: Handle Missing Values\n",
        "\n",
        "    # Identify columns with missing values\n",
        "    missing_values = df.isnull().sum()\n",
        "    print(\"Columns with missing values:\\n\", missing_values[missing_values > 0])\n",
        "\n",
        "    # Handle missing values: Use median for numerical columns and most frequent for categorical columns\n",
        "    numerical_cols = df.select_dtypes(include=[\"float64\", \"int64\"]).columns\n",
        "    categorical_cols = df.select_dtypes(include=[\"object\"]).columns\n",
        "\n",
        "    # Impute numerical columns with median, and categorical columns with the most frequent value\n",
        "    imputer = SimpleImputer(strategy='most_frequent')\n",
        "    df[categorical_cols] = imputer.fit_transform(df[categorical_cols])\n",
        "\n",
        "    imputer = SimpleImputer(strategy='median')\n",
        "    df[numerical_cols] = imputer.fit_transform(df[numerical_cols])\n",
        "\n",
        "    # 2. Handling Categorical Data: One-Hot Encoding\n",
        "    print(\"\\nCategorical Columns:\\n\", categorical_cols)\n",
        "\n",
        "    # Apply OneHotEncoder to categorical columns\n",
        "    encoder = OneHotEncoder(drop='first', sparse_output=False)\n",
        "    encoded_categorical_data = encoder.fit_transform(df[categorical_cols])\n",
        "\n",
        "    # Creating a DataFrame for encoded categorical data\n",
        "    encoded_categorical_df = pd.DataFrame(encoded_categorical_data, columns=encoder.get_feature_names_out(categorical_cols))\n",
        "\n",
        "    # Drop original categorical columns and concatenate the encoded columns\n",
        "    df = df.drop(categorical_cols, axis=1)\n",
        "    df = pd.concat([df, encoded_categorical_df], axis=1)\n",
        "\n",
        "    # 3. Handling Outliers: Using Z-score (Optional - can be added if needed)\n",
        "    from scipy import stats\n",
        "    z_scores = np.abs(stats.zscore(df[numerical_cols]))\n",
        "    df = df[(z_scores < 3).all(axis=1)]  # Remove rows with outliers\n",
        "\n",
        "    # 4. Data Transformations: Min-Max Scaling\n",
        "    min_max_scaler = MinMaxScaler()\n",
        "    df[numerical_cols] = min_max_scaler.fit_transform(df[numerical_cols])\n",
        "\n",
        "    # 5. Data Transformations: Standardization\n",
        "    standard_scaler = StandardScaler()\n",
        "    df[numerical_cols] = standard_scaler.fit_transform(df[numerical_cols])\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "# Apply preprocessing for Diabetes dataset\n",
        "diabetes_df = preprocess_data(diabetes_df)\n",
        "print(\"\\nPreprocessed Diabetes Dataset:\")\n",
        "print(diabetes_df.head())\n",
        "\n",
        "# Apply preprocessing for Adult Income dataset\n",
        "adult_income_df = preprocess_data(adult_income_df)\n",
        "print(\"\\nPreprocessed Adult Income Dataset:\")\n",
        "print(adult_income_df.head())\n"
      ]
    }
  ]
}